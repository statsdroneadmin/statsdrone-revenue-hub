koray-tugberk-gubur-final-2

\[00:00:00\] I believe the majority of them already left already. Left,
SEO. That\'s why actually the industry right now has a better focus for
engineering and they have a higher way, higher respect. Welcome to
Revenue Optimization with Stats Drone. This affiliate marketing podcast
is brought to you by Affiliate Track, which is an affiliate O link
research tool and affiliate finder, and also brought to you by staffone,
the best stat.

\[00:00:28\] An analytics tool for affiliates, agencies, affiliate
networks, and affiliate programs. Let\'s start with what we were just
chatting about like two seconds ago, which is like, you know, I, I\'m
building a, uh, a product that, uh, scrapes the internet of just
affiliate sites. Only. It has the affiliate link linking to a product,
whether it\'s like casino SaaS, uh, SEO affiliate network.

\[00:00:52\] And we\'re also downloading the page titles, and you\'re
just telling me that like the, the capabilities of these page titles is
immense because the, the basic search is one thing, but then there\'s
the semantic search, which is like, what is the meaning behind it. So
I\'m looking at actually vectorizing our own data, which is gonna be a
lot of work, but I think it\'s worth it, and I\'m assuming that\'s worth
it.

\[00:01:13\] I believe, uh, actually every EO should be doing it. Like
around four years ago, I created a GitHub repo. It\'s still actually in
my profile in GitHub. They can check username, which is KT G one. Uh, I
called it actually search beat, which means search engine result page be
tank, which means that actually I just, because in that script I\'m
checking actually search results every second.

\[00:01:35\] Every second I search it. Then I take the data every
second. The main third there is you realize that after a point, even
every second, the rankings are keep actually changing and there is a
pattern in these ranking changes. And after getting, let\'s say 60,000
snapshots for the data, I was able to actually create the animation of
these ranking changes by seeing that every certain site is changing
their place with another certain site.

\[00:02:01\] It\'s not randomly changing. There is a pattern of these
ranking changes from second to second. Another thing is that when I get
all these data from the serp, I was also scraping the results to see
actually why these websites are changing with each other. For instance,
the second site suddenly becomes seventh.

\[00:02:18\] Seventh becomes the second, and why actually they\'re
replacing each other based on this, let\'s say data, and I was checking,
let\'s say whether they have a number in the first sentence, whether
they have uh, let\'s say a certain predicate in the title pack or
whether they have an HTML form element converter or any type of input
area.

\[00:02:37\] If you\'re able to basically run certain type of, let\'s
say, similarity checks or certain type of, uh, let\'s say into attribute
relations, uh, based on these, uh, let\'s say data that you have, you
can actually run these data with the historical changes of Google and
you can see what websites are actually increasing in the rankings and
what website actually are not performing that well, which will be a
great actually snapshot of everything.

\[00:03:01\] Other way you have to spend like your three months. Click
here, click there, check this, and check that. And if you have the data
already with your tool, it\'ll be helping actually greatly for the plate
marketers. Okay, that was called Search B. Uh, search B. Search B. Let
me just find it. Search B. Yeah, maybe I have, I think I\'ll be able to
find it.

\[00:03:23\] Yeah, it\'s in my basic GitHub. It\'s Target there and I
created it like there is also a webinar that I did earlier with Rank
Sense from Hamlet Patista. Okay. He\'s not around, uh, with us anymore,
unfortunately, the digital COVID, uh, situation. Uh, but he, he was also
doing great things here and I just wanted to show him to this.

\[00:03:41\] Then he wanted to do the webinar as well. Okay. So, yeah,
like I said, this, uh, I, I went down a rabbit hole a couple months ago,
spending more time doing, um, uh, building products with AI tools. And
then I\'m reading a book and the book is called, um, Symantec AI Search
with Vector Databases. By, I don\'t know if I\'m pronouncing the name
properly, but it\'s Amal Boyt, B-H-O-I-T-E.

\[00:04:05\] Uh, it came out recently and uh, I\'m doing this because of
that project I mentioned before. So I\'m like, okay, I need to start
analyzing databases and getting better with like, um, you know, just
doing search. So what you just said, uh, a couple minutes ago. So would
you say that people should take the content of their own site and also
vectorize it and maybe produce a better search engine within their own
site?

\[00:04:28\] Sir. Uh, if you\'re a programmatic SEO site, let\'s say you
are ranking for 7,000 set trains like in the CBD nh, in that case,
managing that content is gonna be really hard. If you have 40,000
products in your e-comm site, again, it\'s gonna be very hard for you to
actually manage everything. If the project site is bit, I will
definitely vectorize it and I will actually answer, standardize my
sentences, for instance, when I create a templated content.

\[00:04:56\] To decrease the iveness and increase the ality. I use
certain type of synonyms or I change word orders and I try to add also,
uh, let\'s say different criteria because in Google\'s language system
they have four main actual principle. One of them is factual content,
opinionated content, so structured content and unstructured content,
which means some sections of the content should be tables and the lists,
which is sub structured.

\[00:05:24\] Some sections should be paragraph and some sections a
specialist should be reflecting opinionated angles, uh, perspectives and
the experiences as happens in the Reddit or Quo or any type of social
media site. You should include these angles too. And when I do these
type of factorizations, I\'m able to see the personage of factual
content or percentage of opinionated content, which actually helps me to
correlate it with the affiliated, especially for the affiliate industry,
which is important.

\[00:05:53\] Because since 2023, the, the content that is factual with
certain perspectives also reflected in the language is actually favored
by Google. A, especially user generated content heavily as being
promoted already. Even the Google\'s API link, if you go to the
Google\'s content, API link for content warehouse, API link, and if you
search that UGC, especially UGC, change frequency.

\[00:06:18\] You will see that there are lots of metals there to see
actually how ent that the user generated content is changing there. If
you go to the Google\'s quality rate guideline, you will see human
effort. Total human effort is a really important signal and you can see
also content. Effort is a property in API lead and they say that content
effort is measured with large language models.

\[00:06:41\] So in short, vectorization will be very smart, especially
changing thousands of pages programmatically. While also doing that, try
to decrease repetitiveness to signal orality as well. Okay. That was
pretty heavy. Uh, we, we were just kind of like joking earlier that, you
know, as I was studying this stuff and reading this books, I\'m like,
wait a minute.

\[00:07:02\] You were talking about this stuff like four years ago or
longer. And it\'s like, you know, I, I thought I understood semantic
seo, but now that I\'m going deeper down the rabbit hole of studying
like how Google works, um. Vectorizing of content, um, the databases.
Um, I realize like it\'s a lot deeper. And I think you said earlier that
you believe that a lot of people didn\'t understand s se semantic SEO
back then, and maybe a lot of them still won\'t today.

\[00:07:30\] I believe the, the majority of them already left, already,
left. SEO uh, that\'s why actually the industry right now has a better
focus for engineering and they have a higher, way, higher respect. I
already know that. Actually, when I did the interview with Matt Ide
years ago, I know that actually some people who are saying that, oh,
topical maps or topical authority, it\'ll be just for seven days thing.

\[00:07:51\] People will forget that. And these people, right now,
they\'re trying to sell topical maps and they\'re trying to actually try
to own even the concept of topical authority. And yes, years ago when we
were explaining these things, some people were claiming that we are
trying to make the SEO harder. Now, actually, we were trying to let you
know that these are coming for your.

\[00:08:10\] Way and people who saw it, they joined the community and
they basically do a great work. Right now we published, as I said
earlier, to like around 400 success shares in the community publicly.
And uh, the ones that they didn\'t follow, I believe they left the
industry already and or either they\'re trying to uct from a certain
level, but I can tell that especially if you started year around 2012,
13.

\[00:08:34\] Uh, I usually see two type of people like there. For
instance, in our mastermind in Turkey, there was a person I can name
Luke Bastin. He\'s from UK and he\'s a great person and he actually
improved himself greatly. He studied the course. He even went to do
actually, uh, information retrieval conferences. And he said with that,
uh, professors in the area of information, Val, they actually hate SEOs.

\[00:09:00\] Whenever we go to a conference, we try to monetize their
knowledge and they hate from that situation. So Luke Bain here is a good
example. He changed, he started on that era and he changed, developed or
developed new skills and understanding and majority of them, the people
who start year around 2000 tens, I believe they still have old habits,
uh, and majority of time left SEO by saying yes, or is that already, but
I can tell that.

\[00:09:27\] The year that people claimed at SEO O is, that was the year
that actually we did the most money already. So I\'m very happy that it
just keep dying. Yeah. And, and the irony, would you say this is true or
maybe not true, that with the new AI tools that are available, that
it\'s actually making semantic SEOA lot easier to get into?

\[00:09:47\] Like a lot easier to understand maybe even the research
itself. I actually agree with that out of three, four reasons, because
when I was starting these things around 2017 to just read a single
patent, I was spending my horse because you need to keep everything in
your memory and you need to remember, okay, I, I remember this engineer
and he mentions this.

\[00:10:08\] Then there is another patent that mentions the same thing
and what is the relation between these two engine? It was like a
journalism I could analyze you even, I dunno, is actually government in
the same way. It was a heavy work actually. Today you just actually give
a pattern to JGBT and tell, explain it to me.

\[00:10:27\] And he actually explains everything to you. And then also
he, it tells you what other patterns exist from the same engineers. It
makes things very, very easy. I can tell sometimes, of course, it, it is
hallucinating by giving some fancy random verse that doesn\'t have a
proper meaning on that section. You should be, of course, cautious.

\[00:10:45\] But I believe it, it made everything way easier because you
can give as. Pro type of a paragraph to she GBT and ask the chair GBT
basic, what are the triples here entities, the attributes, or what are
the sentence, let\'s say number of unique verse in this area, or what
are the, let\'s say hyper NIMS or the hyper NIMS and their past there.

\[00:11:05\] And you can see the anato of semantics in every text unit
easily with the L lms. So it makes it easier, in my opinion, 1817. Then
would you say that can, like, are we here today where I can go into
Gemini? Perplexity big. Okay. I need you to act like you are Kar and I
want you to be my, my SEO advisor, um, analyze my site, what should I be
doing?

\[00:11:29\] Read all of RA\'s, uh, material, uh, download all the
podcasts through, what is it? Notebook, LLM, and like they do it
already. My core minutes already do that. And they keep sharing actually
my core box basically. They call it and they, it also works too because
for instance, I don\'t remember every podcast about it, like through the
years, but AI remembers and it size these things very good in a very
good way and finds all the connections and suggest in every tructure
where I can say that actually it already works and many people in our
company already actually is using.

\[00:12:03\] I, I need to look up some cry bots, but, uh, I did try to
try a couple examples of that before recording, so I was like, I\'m sure
I could do this right now. Yeah, definitely. I believe something. Okay,
so over the last couple years I\'ve interviewed so many different SEO
people and there\'s always been constant talk about both AI and AI with
content, uh, generation.

\[00:12:23\] I\'ve been personally scared about using AI because I\'ve
seen some people brag about how they used AI to make all this money and
then they went quiet because their site got destroyed and I\'ve seen a
lot of destroyed websites. So is there a right way of do of not only
using AI for content research but actually creating content itself?

\[00:12:41\] I believe there is, because we created the actual AI
websites in 2021 way before chat, GBT and I explained these actual
websites in my gon speech in 2023. I remember actually how people were
shocked on that speech too, because they sold it already because they
were already discussing this, like, is it safe or not?

\[00:13:00\] And when I showed them the websites that actually already
are hit even two years earlier than JGBT era, they were understanding,
okay, this is already actually covered by Google, but the main thing
there is they usually cover it from your momentum. Because when I
created a topic lower authority concept, I say that there are three
principles.

\[00:13:17\] You cover it actually wider, you cover it deeper, and you
cover it faster. The fast section, I called it momentum. If you cover a
topic, let\'s say you publish 8,000 uh strains pages on one day.
Initially, it ranks really greatly. It indexes very fast. But after like
around average, six weeks later, your website is gonna be hit and it\'ll
be dropping in a very great way too.

\[00:13:40\] So that\'s why I usually suggest actually for momentum,
stay in the human range. Don\'t publish everything at the same time, but
just distribute it at a time. The second part is that the humanization
is a big part because we always have a blacklisted. Blacklisted nouns.
Blacklisted adverbs, blacklisted adjectives.

\[00:13:59\] Because if you look at the ai, it is actually called, uh,
statistical semantics because AI distributes certain type of verse
together with certain co-occurrences. This usually called actually style
and metric. It has a style already. When you see that style, when you go
beyond that actually, uh, let\'s say ordinary people\'s angle, and when
you see actually the an anatomy of the text that it creates, you\'re
able to actually hide the signatures in a better way, because I\'m able
to say that never use this word, always replace it with one of these
actual synonyms.

\[00:14:31\] You\'re able to create a decision three for your own
industry by giving an SEO dictionary sentence structures. Order of these
sentences. And you can always actually create unique content thanks to
that. But you should have very centric system instructions and a
various, let\'s say, a good, uh, black listed word, uh, component to
actually guide it in a proper way.

\[00:14:53\] It works already. So maybe a quick example of this would
be, let\'s say if you want to do 8,000 affiliate program reviews, you do
it all at once. You\'re risking uh, a problem. But in order to get
through 8,000 human, you know, reviews of 500 words, that\'s gonna take
a long time. So maybe as an idea that you could kind of take like a,
like create mini databases where, you know, someone\'s manually going
through the current site, um, they\'re trying to document what they see,
maybe even what\'s been written on the internet about them.

\[00:15:21\] And then kind of like do a mini summary, feed that into ai
and then use that. For, there is good example site for it. Actually. I
always give that website as a bad example and as a good example though,
it is top firearms reviews.com. It should be as much as I can remember.
It\'s a good example because it\'s also programmatic.

\[00:15:39\] It always uses actually Amazon reviews. Okay. In my SoFi
speech in 2024, I explained actually how we use existing reviews from
Amazon, Reddit, or other places to secure all of them and combine them
with our large language model. In a very unique way, in a way that
actually Google sees it user generated content.

\[00:15:59\] Okay. It\'s originative. It also does the same thing. It\'s
also a better example because if you check the way back me data for the
era that they are losing the rankings, you will see that once they get
the rankings for TA firearms, they also start to to review hotels,
bicycles, wood bags, et cetera. But so it was diluting the topicality.

\[00:16:19\] Decreasing the site focus score as the con uh, API actually
says, and they were hit. Once they removed this unnecessary content,
they came back. One more thing is about the images. Google doesn\'t
index every image, and when they go to the Amazon reviews or products to
the page 56 7, you will always see unique user generated images there.

\[00:16:41\] And that unique images on your pages also contribute to the
uniqueness and the ities who seize that image first time. On your page
as well. So these type of many other angles actually can be used as
well. Okay. Well I\'ll give you an example of something I\'ve done, but
I haven\'t published it yet, but now I need to publish it.

\[00:16:58\] So I took, uh, I was doing a presentation at a Sigma
conference, uh, last year, and the topic was why online casinos close.
So I ask gamblers database lcb.org database. We also have a database of
closed affiliate programs. And I said, what\'s the signatures behind it?
So, of course I went, scraped a lot of data, ran a lot of Python, and
then I started looking at, well, what were the signatures?

\[00:17:21\] And one of the signatures that came to the top was, uh,
most of these sites had really bad terms and conditions for players that
said, uh, you can\'t cash up more than like \$2,000 per day, or 5,000
per week, or 10,000 per month. It was pretty bad. And it, that was
actually most of the, the, the cohort. So I think by publishing that
data could be useful.

\[00:17:42\] I think another example, uh, just to use your example,
would be taking casino complaints, which is ask gamblers lcb.org. Casino
guru. I mean, I don\'t understand why people don\'t do this. Like if I
was in affiliate today, I would create an aggregator site and say, I\'ll
tell you everything you need to know about all the complaints, not just
one site.

\[00:18:00\] That\'s true actually. And in one, actually, SaaS, for
instance, in the online dating industry, it is the main competitor of
Tinder. I can\'t give the name due to the NDA. On this company, for
instance, when it comes to the subject of senior dating, we edit some
design elements to the page. These design elements actually have some
polls, which means that actually, let\'s say we ask a question like,
what is the best place to meet with seniors over 60 years old?

\[00:18:24\] On that answer, we don\'t answer it. We just give, let\'s
say options from you. Choose the answer. On that poll, we show the
percentages and AI is automatically rise the paragraph based on the user
inputs, which Alpha has actually user generated content angle with
answer. Uniqueness also shows the engagement.

\[00:18:45\] And at the most bottom part, we also add the most ask
questions directly as user generated content. And then we use directly
an entity person from the Google Knowledge graph on these topics,
especially. To answer these questions as well, but this can also ask
basically human effort. One more time too. So many people still try to
rank with ordinary block layouts, so try to always input these polls or
crease or some forum components as much as possible to avoid some
filterings of the Google system today.

\[00:19:18\] Yeah, but that\'s also a great content generation idea
\'cause I do polls on LinkedIn. Sometimes the answers I get surprise me.
I\'m like, I had no idea this is what I was gonna get for an answer. And
because I get those answers, it changes, changes a lot of things for me.
So I think, I think this would be a total content playbook here.

\[00:19:37\] I hope one day people will be implementing these more. I.
I\'m gonna find clever ways of doing it and AI tools make it, uh, really
easy. I\'m actually gonna experiment with the, the podcast website we
have now. So I built it in. I\'m pretty good with code, but I actually
went to Lovable and it\'s just super easy.

\[00:19:53\] Always really surprising, but good actually, and it\'s able
to integrate everything with GitHub WebPress or whatever CMS that you
use is, is really good strength there. I, I\'m definitely gonna do that
there because I\'ve already, um, I\'ve used the RSSV to auto generate
each podcast episode, and then now I\'m going to like, you know, we\'re
talking Geek Talk.

\[00:20:14\] I\'m gonna go into N eight N, download all the audio,
convert it into text, and then I\'m gonna do a whole content playbook,
which is, it is another question I\'ve got later on, uh, for this. Okay.
So I want to talk about. I was actually using a lot of AI tools and I
was starting to build some Google Search console, um, uh, dashboards.

\[00:20:34\] And as I was doing, I was like, wait a minute, is this
gonna be a waste of time? Like, is Google Search Console gonna be
totally different in a year from now? So where do you think a tool like
Search Console is going to be as we change from like the regular Google
to, you know, the AI version? So the first thing there is I believe over
three years, search console is already not giving.

\[00:20:57\] Maybe 40% of the real data or the value I can say as the
first thing is there. There are so many new search features. We even
didn\'t name them as SU industry, unfortunately. I will, I have my own
dictionary there. Some of the names that I use might not be that clear,
but for instance, when you search for the, uh, let\'s say the best, uh,
SEO tools, let\'s say, they usually give all the brands at the top.

\[00:21:22\] It is actually in the patents, they call it generated
ranked entity list. It\'s the official name in the patents. My naming
there is based on hyper Serb I call it because it\'s like a SRB inside
another srb. That\'s why I call it like hyper serp. And when you click
to the one of these brand bubbles, it opens another accordion and gives
you the three top results for that index as well.

\[00:21:46\] Let\'s say you search for best SEO tools. I don\'t want to
advertise anything there, but let\'s say you do one thing. That actually
shows you three results from that specific index, which means actually
it connects an index to the another one. And technically right now, none
of the SEO tools actually track what entities appear on that list.

\[00:22:06\] And inside that actually bubbles. What it ranks. It\'s not
also not known. If you go to the, what people say surf feature, which
usually LinkedIn, TikTok, Instagram rated type of places are ranking
there. We still don\'t know actually which brand social media or which
brands in ER is ranking on that part.

\[00:22:25\] Nobody cares. Nobody checks, and I believe Google Search
Console also doesn\'t give this data on purpose because if they start to
give that data, SEOs will realize it\'s important. Then we will be
asking even more. So they also want to help keep us in that dark zone.
The one key difference is that at the eighth, December, 2025, they
announced that.

\[00:22:47\] They are integrating social media channels into the search
console, and I believe it was the biggest change of entire year, in my
opinion, because, uh, in 2002 23, they announced helpful content system
by saying that helpful information for people on social media and forum
sites. This was the exact phrase.

\[00:23:09\] And still they keep doing it because Google\'s motto is
very clear For SEO or for search, it is basically people, for people in
the search, they want people to create content and they want people to
find people content and social media sites. And the forums are the main
principle right now for them, and that\'s why they\'re integrating your
YouTube channel.

\[00:23:31\] Your Reddit will be the next one and other social media
channels to do your search console today. If your YouTube channel
basically gets more clicks from Google, they will be telling it to you
and it helps them for two reasons. One thing is that the search console
will be topic based, which means that in the future, rather than telling
you what query brings you the most clicks, they might be saying what
topic is bringing more clicks as well.

\[00:23:55\] The second thing is that they want you to also, they want
you to create more content by showing your face in a video, in a
podcast. They want you to create more content for their integrated
platforms like YouTube or the Reddit. If I add one more thing there is
if your website gets fewer clicks due to the AI search features, when
they give you the social media clicks in your search console, they\'re
actually telling that yes, your website gets fewer clicks, but your
social side getting more.

\[00:24:25\] So focus on there. They\'re trying to tell. In 2019, in one
case that I say that if you have a YouTube channel, there\'s a higher
chance that you can actually save yourself from these core updates
because ownership of a active YouTube channel pro directly proves that
there is a brand attribution and there is a business behind actually
everything that you do as well.

\[00:24:48\] So I believe the search console will be very much more
integrated with AI search features. So you will be using all these
filtering. With AI or LLMs, it\'ll be a done. It\'ll be a kind of
conversational data analysis tool, not for the queries, mainly for the
topics, and it won\'t be only for your side, it\'ll be also for your web
entity, which involves all of your also social media channels and maybe
even beyond as well.

\[00:25:17\] Okay. That was pretty heavy, but. Um, that\'s actually
something, uh, I was actually planning to do on that initial project
where we, we scrape and we find all the affiliate sites, like we\'re
actually scraping all their social contacts. Like do they have YouTube?
Do they have Facebook or X or Reddit and contact forms and addresses.

\[00:25:35\] And we, I believe there\'s a correlation there, but we
won\'t know what the correlation is until we actually start saying,
here\'s the field sites, here\'s all the links they have on all their
pages, and here\'s everything. So I think there\'s gonna be some.
That\'s obvious, I think. Um, but I think a lot of people, they need to
see the data before they, they have that aha moment.

\[00:25:54\] Yeah. If I\'m be maybe one more functionality for that
tool. If you allow people to integrate their search console data with
your technology, and if they also give you the log files, you can see
actually whether social media links help Google Vault to crawl more URLs
from their, actually let\'s say, uh, website abroad.

\[00:26:16\] Because comparing some data like this, let\'s say there is
a URL. It is being crawled by Google Bot higher frequency during actual
social media shares because if you go to the search console, use your
inspection tool, sometimes you will see that actual TikTok or Instagram
comes in the referred page section.

\[00:26:37\] They find your URLs from socials and then they start
actually crawling there. You can decrease the indexation delay. You can
increase number of S that you rank through actually getting these links
from socials. I\'m not talking about link juice or page ranks here.
It\'s different. I\'m just talking about exploration of new content and
forcing Google to crawl it more regularly as well.

\[00:26:59\] That type of maybe check, answer will be filter too.
That\'s actually a great idea to ask, to say, Hey, do you want to
connect your search console data? But it goes without saying that the
user needs a benefit from it, but. I do think, like I\'ve actually
built, uh, some of these console, uh, reports where it\'s like, okay,
you know, you know how your data\'s only, what 16 months of console data
before it disappears?

\[00:27:21\] And I do believe that the daily console data is useful, but
Google doesn\'t make it super easy for you to export just the daily. So
you have to pull the data once a day. And I\'m basically, you\'ve
probably already done this before, but uh, I\'m basically building this
stuff. So maybe there could be some connectivity where it\'s like.

\[00:27:37\] How do we make this useful for someone to connect their
search console? Maybe if we give them this new, um, console reader or
console report for free, that might be the intended to make, Hey, I have
a reason to actually upload it. And maybe there\'s some sort of social,
not social, but maybe there\'s some sort of big data sharing where their
data\'s not exposed, but it\'s put into a, a giant database.

\[00:27:59\] Correct. Many other things can be done with the search
console console data. I believe, for instance, you can always create
custom collect curves. Every seven days, you can tell them actually what
pages are increasing in impressions from what queries, or you can give
them number of URLs that give, that takes impressions for the same
queries, which actually shows micro cannibalization.

\[00:28:18\] You can always actually, uh, easily export your data to the
BigQuery automatically as well. And from BigQuery, you can always try to
actually see, for instance, there is a seasonal event every year for
some certain, certain, let\'s say, types of situations. You can see
actually how your CTR is changing during these seasonal events.

\[00:28:38\] Or also you can import your log files and you can see
actually your traffic data and the crawl data, how they are correlating
with each other. Many other things actually can be done there. Actually
a lot of data, especially your actually vector database. Uh, let\'s say
you vectorize my content and you have my search console data as well.

\[00:28:58\] You can sometimes, uh, because. Semantic. Actually, if you
want to do Semantic seo, the first thing that you should be doing is
decrease the dimens reality, because I can\'t keep adding new data, new
correlations, new causations, many other things. I, my security in the
GitHub, I have like 2000 columns. I, I have taken everything there.

\[00:29:21\] But actually seeing the most important thing there is you
don\'t need to check 2000 columns to see. How this website is ranking or
why it is not ranking, it should decrease the dimensionality of the
data. You can just check some simple things there. For instance, in a
simple way, just compare actually your growth frequency to the actual
content update, let\'s say, or your update frequency compare, let\'s say
your number of embeddings.

\[00:29:47\] When you vectorize the content, compare your number of
embeddings to the number of queries that you\'re ranking for. Or compare
your, let\'s say, number of heatings to the number of queries or
percentage of this impression increases as well. All these actually will
be more helpful for you to see what I should be increasing most in that
area.

\[00:30:08\] If you start to deep dive into the every punctuation, every
word, every in today\'s reviews, it\'s not humanly possible. Uh, on that
level, I can say. Yeah, but I actually think that would be pretty cool
to give someone the power to be, Hey, here\'s your page. You know, the
data technically is available in search console, but it requires, I
think, a little bit of data manipulation to see, here\'s your pages and
here\'s what you\'re, uh, getting traffic for both in terms of
impressions and clicks.

\[00:30:33\] And I think if people had easier access to this, this would
actually educate them on the actual basics of semantic SEO to be like,
oh, I didn\'t realize this was an important term. Or, I mean, I don\'t
know if this is possible. Do you think it, there\'s a future where. The
search comes in from something really obscure, so it\'s not a lot of
clicks, but maybe the value of the click is worth more.

\[00:30:54\] So we have a tool that that has dynamic make variables, so
it\'s click id level tracking, so we can actually map each individual
click. Now, I don\'t know if Google search consoles already switched to
by the minute or real time data because if you actually know what click
came from, where maybe you might be able to match the search query to
the actual click, going to the affiliate program and actually getting
the revenue associated with that click.

\[00:31:17\] It is, uh, it\'s hard to do because the thing is that, uh,
they\'re anonymizing or pay anonymizing the data. Uh, if you manage to
do that, they will be very against it. They might sue you possibly, or
hide it, basically from them at least, or, or acquire me. Yeah, that\'s
possible. I mean, you can try to run maybe timestamp similarity.

\[00:31:41\] Yeah. There is an organic click on a certain timestamp. If
you are able to also see the session timestamp and if they are close to
each other, uh, closer than, let\'s say one second, probably it\'s the
same user. And from there you can assign basically this user Id belong
to this click, and from there you can actually correct them.

\[00:32:01\] Legally, I\'m not sure how it\'ll be. Yeah, it goes without
saying. You have to start with the user saying, do you agree to these
terms and conditions and cookies? And you start there with permission.
And then once you have their permission, I mean, that would be
phenomenal to be able to match the revenue associated with the search
term.

\[00:32:19\] True. There is one small tool actually, like, and I guess
it was a keyword hero. Uh, it is a partner of Google Analytics. Four,
and they are doing it, but they also do it in a, like, not like for
every collect, like a level of clicks they\'re trying to give you. Uh,
but they are having a special permission from Google Analytics as a
partner.

\[00:32:41\] And even it doesn\'t do more than maybe 2.5 person, I can
say, okay, I, I\'ve got some homework. I\'m gonna give it a try because
I\'m actually building another. Small project where it\'s basically
like, it\'s in iGaming, so obviously you have recurring revenue, which
is valuable to an affiliate. So the idea is that when you have a
newsletter, you\'re usually sending one tracking link to your entire
database.

\[00:33:05\] So all users, the revenue ends up in a single bucket. You
can\'t, you can\'t separate it. But with click ID level tracking, what
you do is you basically are able to assign a unique click ID to each
email. So if you signed up to one of my newsletters that I\'ve built on
the side. It starts with permission and then once you filter through the
flow, uh, i, I sign a unique ID associated to you that ID is put inside
the tracking link and that tracking link shows up into my revenue
reports.

\[00:33:30\] So I could act, I could actually see your last deposit. Um,
so I know if you stopped playing at the casino, whether the casino
removed you from the database because they, they wanna steal from me or
you actually generally stop playing. So, um, think there\'s, that\'s a
goal. Great. Actual surveillance. In that area.

\[00:33:48\] It, it might be closing a very good, good cap gap,
actually, or monetization as well. It\'s, it\'s a nice, a nice design.
Yeah. And then of course, uh, the thing that you could build is taking
the user, going back to the website. As long as they\'re logged in, then
you can start putting that parameter in all the pages and going, what
pages and content are they consuming?

\[00:34:07\] As they send emails to you. So rather than sending a
newsletter like email, you actually send a conversational one. Like, Hey
Aria, how\'s it going? I\'m curious to know what games do you like? And
as you reply in text, we convert the text, put it into a database if and
when it needs to go into a database. And then, uh, and then I think you
can see why went down the rabbit hole of like, okay, let\'s start
studying Rag and Vectorizing and all these databases.

\[00:34:30\] And so yeah, definitely that\'s where I\'m at. Nice design.
I believe you can, if you can basically create it, I believe it\'ll be
virtual, really good amount of millions of dollars. Yeah. And I\'ve
actually built another component of it, which is, it starts by taking
the user\'s email and then basically it goes through NN.

\[00:34:51\] So it\'s like you get one of four messages and it\'s all
like ab split testing. And then, um, based on your response, like if
you, if you view the page or if you click on the link. Um, that all goes
back into the database. So I built a database. I used the Postgres to
build it \'cause I thought it might be better when it comes to this AI
rag vectorization.

\[00:35:11\] Um, of course you can use almost anything, but um, that\'s
where I\'m at right now. That\'s also a good plan as well. And also you
can always defend yourself against the casino or whoever base you are
athlete with. So it\'ll be very strict proof. Actually, I think. Then
this is where it can get more, uh, interesting.

\[00:35:31\] So not all programs give you click ID level tracking. So
there\'s post backs over here, dynamic variables over here. And then
there\'s a lot of programs that don\'t have either of them. Now, if you
have a player that\'s worth a lot of money, what you could do is you can
go into the affiliate program, create a hundred tracking links in
advance and say, I only want to assign these links to players that I
know are actually worth something.

\[00:35:50\] So you\'re, you\'re getting the equivalent of a click id
level click, but you\'re doing it manually. It\'s still worth it. So if
you\'ve got a player that\'s, uh, spending let\'s say 10,000 euros per
month, yeah. Um, it\'s worth giving them a custom link. You know, it\'s
worth actually going back and VIP customers click, VIP customers deserve
VIP ID basically.

\[00:36:10\] Yeah. That actually, uh, segments into a question I have
about personalization, which is the newsletter is a personalization
concept. Um, but do you think that there\'s a, a new world of
personalization in terms of like. Creating the content and going, how do
we hyper-personalized this to users with and without them logging in, if
that makes sense.

\[00:36:31\] So when you mean the personalization, do you mean
personalization of the content on the site or personalization of the
content on just the newsletter or more on the website? More on the
website. That part is a little bit actually, uh, bringing me to do some
of my latest SOPs because I started to differentiate domains from each
other.

\[00:36:51\] Some domains, and technically, of course, as I said earlier
too, what you do for AI features of Google and for the regular,
traditional search, it\'s not that different. To rank in the ai, you
have to rank your document. If you rank your document, your passages are
gonna be processed and ranked and retrieved.

\[00:37:10\] And if your passages are ranked in the features in the
past, where the people will also ask, also the reads lived and
generated. An augmented passage also is gonna be citing you as well. For
these money sites, usually you also have to balance some sections.
Let\'s say I\'m searching for current accident attorney Houston for
Filipinos or Filipino victims, because Filipinos sometimes actually just
want a Filipino lobby for themselves.

\[00:37:34\] And if you keep adding every nationality to your web
document, then actually you are gonna be decreasing the relevance while
increasing what Google calls. So the personalization that you do on
certain valuable domains. Rather than making it very explicitly, you
have to annotate it basically by adding the most important ones and
annotate the rest from that class basically.

\[00:37:57\] And there is a second group of domains that actually I
call, and I started to call them either permanent EMDs or temporary
EMDs. If it\'s a permanent exact mesh domain, you can check more of
them. For instance, also to text.com. We ranked it like around just two
months, and right now it\'s around 6,000 clicks, sorry, six days, 6,000
clicks over the exact mesh domain.

\[00:38:19\] It\'s converting really well on that one. For instance,
it\'s a permanent exact mesh domain that we want to also manipulate
every type of surf feature in these ones too. Actually, I try to be
closer to a certain type of vector with your, with my brand attribution,
and the content is adjusted for that. There is also wasteful domains
like call for the wasteful domains.

\[00:38:41\] For instance, I can actually open any page for any long
term question or whatever, and that is actually not even a permanent
domain that much because all of my social media accounts or social media
official accounts or non official accounts, and my wasteful domains that
I call them, they\'re all actually adjusted for creating a consensus.

\[00:39:01\] Around the web by actually creating a surrounding sound
around my brand and also around my topic. It is actually called surround
sound campaigns as well, and we try to manipulate LLMs and reach out to
these people with hyper focus and hyper personalization. Even if that
domain doesn\'t rank for the long term, or even if that domain doesn\'t
rank for valuable query terms, it\'s okay because we target maybe two
words of queries or sentences or instructions.

\[00:39:30\] So these are. Usually, uh, mainly for actually LLM focus
domains, and if you want to do this level of personalization, usually
this is what we do. Beyond that, if I need to do personalization for
every landed user to do my webpage on that segment, I need to usually
use either some directions, which Google doesn\'t like that much.

\[00:39:57\] \'cause they call it sneaky redirection, which might be
causing some cannibalization and also canonization problems. If I use,
uh, some, let\'s say, different content based on the user agents and
user agent, IP address, or user agent location, I need to accept the
risk of being diagnosed, diagnosed as cloaking source, because if I\'m
showing a different something for every user, including also Google user
agents.

\[00:40:25\] It\'ll be a way of actually clocking and if I change my URL
for some of them, but if I keep it, same for some others. Again,
actually it\'ll be seen out dangerous by Google Bot too. To increase
your chance of success there, you can try to see what location Google
Bot is crawling you, and from that location you can always show a
certain type of content.

\[00:40:45\] And for other locations you can show some different content
as well, but eventually in my experience, they will catch. So if the
website is money site, I usually try to not do that that much unless
they are locked in. If they locked in, you are safe. But if you are
solving different things that are not locked in users, I usually prefer
wasteful domains, which means domains that I can waste easily to do
these type of things.

\[00:41:13\] That\'s challenging. I don\'t think I\'ve got an answer to,
to that because like, I\'ll, I\'ll give you the example. Like, we have
our website Stro, we\'re tool for affiliates, but we have a lot of
different, uh, personas on our website. We have affiliates, affiliate
agencies, affiliate networks. We have SEO affiliates, we have PPC
affiliates, uh, affiliate managers, operators, and the software.

\[00:41:33\] And it\'s kind of like trying to create. Trying to keep all
of them happy is not easy. But I have some ideas of what pages some of
them like to go on. Uh, but there\'s a lot of the pages where it\'s
actually suitable for everyone. But it\'s like I\'m trying to go, okay,
how do I create content and keep everyone happy?

\[00:41:49\] Like, do you think that there\'s a way where we could have
like a, instead of a geo bar that says you\'re from Canada, it could
actually be like, what is your ICP might be also, that\'s also in every,
that\'s also working too. But I believe for this issue, there is not a
100% perfect solution. There might be maybe just one thing that also
might be harming less while helping.

\[00:42:10\] For personalization, it\'s something I usually started to
do when these L LMS starts to be more important. I still do it for some
pages, so technically, uh, I just choose some zones on the webpage and I
just do personalization for that section. And the percentage of content
that I change with the personalization is not over 10% of the text.

\[00:42:33\] That\'s the first thing. I never personalize the content or
customize the content from the important heatings or important sections
of the HTML. The third thing is that if I do personalization, I use data
no index snippet, which means I tell Google Bot, if you come to this
page, do not index this section of the HTML, which decreases its
prominence for indexation rank of all ranking purposes.

\[00:43:01\] By using that approach, I\'m able to also basically.
Constraint the personalization to the non-important sections. And I also
tell the search engine, it\'s not for you don\'t index it as well, but
this is the least, or let\'s say most possible healthy version. There
still not perfect, but it might, uh, or at least for LLM angle, it is
working because.

\[00:43:23\] For large language model, sometimes I\'m adding very big
chunk of text at the bottom, but I tell Google Bot, it\'s not for you.
Don\'t inbox it. Don\'t check it. Don\'t care about it. Yeah. So this
type of maybe differentiation with some certain data snippet
instructions actually is helpful. That that might be a good solution.

\[00:43:40\] It\'s kind of like, you know, let Google know that. It\'s
like, Hey, I\'ve got five pieces of content. They\'re all personalized
and it\'s like one of five personas. It\'s kind of like, Hey, if you are
this persona, click here and I\'ll tell you something you need to know
about this page. Yeah. And it\'s not for Google Bot, basically, because
technically if they see something no index to save the cost, they don\'t
even judge it.

\[00:44:01\] They even don\'t check it. They have a kinds of, uh,
basically pattern behavior there. If, for instance, if the page is
index, they even don\'t render the Java secret to decrease the cost. Uh,
so if you say data, no snippet. So the data no index for a certain part
of HTML, they wouldn\'t run a proper algorithm to check what is actually
going on in that area too.

\[00:44:23\] Okay. I\'ve never heard of that before. But you know, as
we\'re scraping all these affiliate sites, that\'s gonna be one thing
we\'re gonna add to the list. We\'ll be like, who, which affiliates do
this? Because my personal take is if it works really well, then we might
see some of the best, um, SEO focused affiliate sites ranking at the
top.

\[00:44:40\] And if they start having these signatures on their code,
uh, we will find it. I believe you can also Googles on, uh,
documentation. They have some of these, uh, these type of things there
as well. If you create some different URLs, uh, with JavaScript
direction, also try to use, there is one instruction that you can use
for Google Bot.

\[00:45:03\] It tells until what time it should be called. Okay. For
instance, you create an alternative version and you redirect on the debt
user, so the debt error. That zone and you can use base like shorter
than two weeks. They are very tolerant for two weeks time zone for AB
testing or for this type of sneaky redirects.

\[00:45:22\] They don\'t see sneaky if it is shorter than two weeks. If
you create an automated URL change system every two weeks, you can
change to the another URL and you can again tell after this way it\'s
not needed anymore. So don\'t try to index it or don\'t try to canonize
it. It\'s just for some small portion of users or limited number of time
days.

\[00:45:42\] Basically, these type of signals actually can, uh, let\'s
say help you to personalize the content without being flagged as
cloaking source in that area too. So, in other words, SEO is dead in
2026. Yeah. I\'m, I hope it keeps dying. As I say, whenever it ties, we
make more money, so, yeah. No, I believe that to be true.

\[00:46:03\] I mean, it\'s kind of weird that I left the affiliate space
and I, I, long time ago I did SEO consulting and I\'d just be like, wow,
if I actually stuck in this space. I mean that there\'s so much money to
be made. Yep. Definitely. Okay. It\'s quite in affiliate industry, I can
tell, uh, uh, for, let\'s say Scandinavian countries.

\[00:46:21\] In iGaming every country. Like for instance, even if you go
to do Nigeria, especially Nigeria, actually, they gamble a lot, but
let\'s say even Somali, even the countries with civil war, they keep
gambling. Yeah. And the, the internet on these countries are virgin and
you can easily manipulate things, direction with hack domains, expired
domains, exact mesh, and many things there.

\[00:46:42\] Uh, so you can use, technically it\'s infinite. I mean, we,
we have so many different types of, uh, affiliate customers. I mean. We
don\'t see their data, but I mean, we, we, a lot of them talk to us and
they tell us what they do and it\'s, um, yeah. People keep asking us
like, they\'re like, so SE o\'s dying, so therefore our business at
risk, I big, if it was at risk, we\'d actually be dropping and we keep
getting, uh, we, we keep gaining more customers, but we actually are
increasing our, at our, our.

\[00:47:09\] Like all the time. It\'s just like, \'cause we have more
advanced features and they keep using them and it\'s like, look,
affiliates is not dying. True. I can also tell maybe one definitive
thing about whether SEO is gonna be dead one day or not, in my opinion.
I say to their new, and I\'m saying actually with very high confidence,
if you want to kill search engine optimization first, you have to change
the economy model.

\[00:47:35\] If you bring communism one day, yes, SUO will be that. But
many other things. As long as you have free markets and the free will
people are gonna be searching for searching. There will be a search
engine for search engine. There will be optimization. It\'s not gonna
change. Maybe you\'ll be searching from your neurons.

\[00:47:52\] Maybe you\'ll be searching that in your brain. You won\'t
be looking at the screen. Maybe you\'ll be using your brain directly
with narrow link or whatever. But even then there will be search engine
optimization even for that too. Eventually it\'s gonna be always
working. So you need to change economy model for till, to be honest.

\[00:48:08\] Hopefully we don\'t get the communism version where it\'s
like, posts on social media can get you in jail. Will your searches get
you in jail, ma? Many other, many other things there actually, I can\'t
say, but I believe that\'s the only way of killing that. Other than
that, I don\'t think that it\'s gonna be ever dead will just keep
changing.

\[00:48:23\] But that will, we also keep existing. All right. I\'m
confident in that. All right, so I\'m gonna wrap up with the two more
quick questions. Um, so with this podcast, like I\'ve been doing this
for two and a half years. I haven\'t actually took a lot of the content
from it, from audio to text. \'cause I used to use Descrip, which is a
lot of work in editing.

\[00:48:42\] But I know that, um, the, the tools now are like even
easier. So I\'m about to build an edit and automation convert it, but I
don\'t wanna just publish the transcript blindly. I want to, I wanna do
lots with this. So what would you advise. Whether it\'s me as a B2B
podcast or anyone who\'s doing a B2C podcast as an affiliate marketer?

\[00:48:59\] Well, great question actually, and again, it is touching to
the my latest SOP, because we created an SOP for law firms, and in that
SOP, we turn every love year first into an entity in the knowledge
graph, and we open official site for them. Then we create all the social
media accounts for them, including I am DB professional account.

\[00:49:17\] Then we add every podcast. By turning every podcast into
entities in IMDB and assigning that lawyer as an actor in the podcast.
Okay, and then to the official site. We also keep adding every podcast
episode, and sometimes we also create a separate site for the podcast
itself too. While doing that, we turn every podcast episode to the text
because we know that when we keep adding this podcast to the Apple
Podcast or Spotify or whatever else.

\[00:49:45\] All of them, basic being consolidated by large language
models and Google. And then they also actually change the large language
model S directly as well. So the text there is actually used by LLMs in
a very good way. We distributed the official side of the entity and to
the IMDB and to the many other social media accounts.

\[00:50:04\] And then we also use certain GPT or N eight N as well to
turn this transcript or transcript of text. To the three floats or to do
Reddit thread or to the quarter, basically pause, and every prompt
basically takes the same text and turns it into something else. Then it
doesn\'t end there. We also take that episode and we chunk it to the
smaller pieces because episode is designed in that way.

\[00:50:28\] And then we also add a kinds of, uh, sound wave to do that,
that thing, we turn it into a video and we post this to the YouTube.
Then also we basically make it YouTube shorts and TikTok shorts,
Facebook short videos, and many other things as well. So it is a kinds
of content reformatting, repurposing, and syndicating with different
angles.

\[00:50:49\] Then you will see that actually you are creating so much
content from alterative sources with all every type of format, like text
content, audio content, video content. Yeah. And then eventually you
start to change the answers of LMS as well, because. The moment that
you\'re an entity and the moment that you have too many documents and
the pages that are mentioning you, a lamp, also start to cite you.

\[00:51:10\] And since we have too many law firms as well, we also say
things like this. A law site says that basically owner of this law firm
from California states that we keep citing you. We keep mentioning you
from other law sites as well, which also creates one more time ization
and also trust around that specific entity and his or her works as well.

\[00:51:30\] So this will be one of the things that people can do. Okay,
so basically if you weren\'t doing a podcast before, this is a great way
to build authority plus content. Definitely. Okay. So I did the right
thing years ago without realizing what I was doing. I was like, let me
just do this and figure it out and try to get some customers and paid
off in more ways than one.

\[00:51:52\] Definitely. Second Ians uh, yeah, so we have, uh, over a a
few thousand affiliate program reviews. We have a site. That we compete
with. It\'s not a direct product compare, uh, competition, but it is,
uh, get lasso.co. So they have affiliate program categories and reviews
of affiliate programs. I do think their content\'s paper thin, doesn\'t
matter.

\[00:52:12\] They rank really well. Uh, what should we be doing to
improve our rankings and authority for, we want to be like the number
one affiliate marketing company, like when it comes to the B2B side. So
in that area, actually I can tell that, uh, many people focus on
actually the text, mainly around 2023. Uh, even the half of the 2024, it
was still the main focus, but right now Google is mainly focusing on
your layout.

\[00:52:41\] Okay? They\'re able to understand whether you are AI
generated or not, from the blog or visual semantics. I will give two
names. One of them is Alexander Nyer, the other one is Michael
Benderski. If you check these two people, you will see actually they are
reshaping the goals ranking algorithm right now, and they heavily focus
on your layout.

\[00:52:59\] If you\'re able to use annotations and specific visual
semantics. By putting the same data in a better sub structured visual
way, you can again, keep increasing your ratings in a better way as
well. I will be focusing on a little bit in layout there. The second
thing is that without bloating the page too much, I will try to add more
information with the same data.

\[00:53:22\] Even if the data is same, you can interpret the data in a
different way as well. You can add different comparisons, different
declarations, or different, let\'s say, uh, clarifications around them.
One more thing is that, uh, defining a concept is always making you an
author whenever that concept exists in the queries.

\[00:53:43\] If you want to be an authority on B2B f, late defining B2B
marketing and also at late marketing and connecting these to each other.
Distributing all these links and alterative back to your review pages
will be a good approach as well in the period. Okay. That was pretty
good. And just something that I wanted to share that because we have
this, this, uh, research tool for affiliates linking to operators, we
want to try to put that data back into the reviews to say what are some
of the affiliates linking to this, this brand?

\[00:54:14\] Um, and then also the increase or decrease of links. We
think that\'s actually a signal where it\'s like, what happens when the
five biggest gaming affiliates remove a brand? That\'s a pretty strong
signal that we don\'t know what\'s behind it, but it could be it. It\'s
just not good. Let\'s put it that way. One more thing is that, by the
way, you can also try to add this user generic content signals by adding
submit a question feature or by asking people, would you vote this rep,
let\'s say ffl program, let\'s say for this, this, this criteria.

\[00:54:45\] Then if you go to the Google, open the base AI overview
future by using, let\'s say, U-S-A-V-P-N or whatever, and just try to
search for this. Give it top to one affiliate programs for these three
criteria. Whenever you change these three criteria, you are gonna see
that the answer is changing, and it means that actually they\'re able to
judge basically for these criteria in a very clear way.

\[00:55:08\] If you add these criteria and comparison for these criteria
definitions for these criteria. Also, if you allow users also review
these programs or products or services for these criteria, that\'ll be a
very good approach there as well. For many SaaS, we use this D top five
up to 20 for this. With criteria results, we these results, then we try
to see which criteria is associated with which product, service, or
brand.

\[00:55:36\] And from there we try to actually exchange the consensus
with the wasteful domains as I explained earlier. Okay. I got lots of
homework to do. I got so many pages of notes, so let\'s end it there.
Uh, Kry, thanks for, for doing this. I wanna pass it back to you. How
can people get a hold of you and tell me what\'s new on your side?

\[00:55:53\] Thank you so much. And I am active in Facebook, LinkedIn,
Twitter. I\'m in other places. And if you want to come join our coach,
topic law authority, or you can join to our community as well. And if
you want to see him in person, you can come to the KU as a Turkey during
the September. Always. We have a mastermind for seven days.

\[00:56:09\] Probably we\'ll be focusing on a launch of a new course and
a new SAS in 2027. We are actually planning for mainly semantics. We are
starting to design it and also coding it as well. But I won\'t, I\'m not
gonna be announced it official until I, I trust the sass as well. And
that\'s it. Awesome. I gotta make my way to Turkey to, uh, hang out at
your event, so I\'m gonna put it on the calendar and if another event
has to move, uh, we\'ll see what we can do.

\[00:56:37\] Thanks so much. Thank you. Thank you as well. Bye-bye.
Damn, that was an intense episode. Um, I told Kakar that, you know, this
would probably be a 20 to 30 minute chat and we went close to an hour.
Uh, we chatted a little bit before and after the podcast recording and
yeah, we just talked about a lot of things in SEO space.

\[00:56:58\] I think, uh, Carra is possibly one of the more
misunderstood SEOs. In the world, um, misunderstood because I think he
attacks, uh, SEO from a different angle, and I think he\'s actually been
doing it in an, an advanced way for many years. I think it\'s actually
now because we\'ve got, uh, the world of AI and people are starting to
talk about LLMs and Rag and, you know, vectorizing databases that all
this stuff RY was working on years ago.

\[00:57:26\] Um, it it\'s almost like it came true. Um, so I, I got a
lot of really good ideas out of this podcast. I hope you did too. Um,
I\'m personally planning to listen to this a couple more times, so the
next flight I go on, I\'m going to listen to this episode and I\'m gonna
take my pen and paper and just write some notes.

\[00:57:44\] So, very grateful to have a, this chat with cry. Um, still
buzzing from doing the recording and he was one of the more. Uh,
downloaded episodes we\'ve had in the last couple years, and I think
this one is probably gonna beat it, and it\'s gonna be just new content
that\'s relevant for today. And for those that have kind of, uh, maybe
thought that, you know, cry was just talking too much about semantic,
SEO.

\[00:58:08\] Well semantic, SEO is a real thing, but it goes deeper
beyond just kind of, you know, doing eat and, uh, topical authority.
It\'s, you can take it to another level. And I think in the world we
live in today with ai, there\'s definitely a lot of opportunities here.
I.
